{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `SkLearn Basics: using Logistic Regression`\n",
    "\n",
    "# <font color=red>Mr Fugu Data Science</font>\n",
    "    \n",
    "# (◕‿◕✿)\n",
    "\n",
    "# Purpose & Outcome:\n",
    "\n",
    "+ Use Binary Classification and go through an example to see how sklearn is used\n",
    "\n",
    "+ Show Logistic regression, NLP and working with spam or no spam messages\n",
    "    + Print metrics such as F1-score, precision, recall\n",
    "    + show 3 ways to get accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "\n",
    "# For file operations\n",
    "import requests\n",
    "import pprint # for pretty printing\n",
    "import os # listing and managing file path\n",
    "import zipfile # for zip and unzip utilities\n",
    "import csv\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt # for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLP\n",
    "import string\n",
    "from collections import Counter\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Training model:\n",
    "# for converting documents in word count\n",
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from joblib import dump, load # save model and load them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get our dataset of Ham/Spam:\n",
    "\n",
    "data_url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/00228/smsspamcollection.zip'\n",
    "r = requests.get(data_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download our dataset:\n",
    "sms_zip_file = 'smsspamcollection.zip'\n",
    "\n",
    "with open(sms_zip_file, 'wb') as out_file:\n",
    "    out_file.write(r.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r--  1 zatoichi59  staff   199K Oct 31 10:03 smsspamcollection.zip\r\n"
     ]
    }
   ],
   "source": [
    "# verify the download:\n",
    "!ls -lth *.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with zipfile.ZipFile(sms_zip_file,\"r\") as zip_ref:\n",
    "    zip_ref.extractall(\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMSSpamCollection readme\r\n"
     ]
    }
   ],
   "source": [
    "! ls data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ham\tGo until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...\r\n",
      "ham\tOk lar... Joking wif u oni...\r\n",
      "spam\tFree entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\r\n",
      "ham\tU dun say so early hor... U c already then say...\r\n",
      "ham\tNah I don't think he goes to usf, he lives around here though\r\n",
      "spam\tFreeMsg Hey there darling it's been 3 week's now and no word back! I'd like some fun you up for it still? Tb ok! XxX std chgs to send, £1.50 to rcv\r\n",
      "ham\tEven my brother is not like to speak with me. They treat me like aids patent.\r\n",
      "ham\tAs per your request 'Melle Melle (Oru Minnaminunginte Nurungu Vettam)' has been set as your callertune for all Callers. Press *9 to copy your friends Callertune\r\n",
      "spam\tWINNER!! As a valued network customer you have been selected to receivea £900 prize reward! To claim call 09061701461. Claim code KL341. Valid 12 hours only.\r\n",
      "spam\tHad your mobile 11 months or more? U R entitled to Update to the latest colour mobiles with camera for Free! Call The Mobile Update Co FREE on 08002986030\r\n"
     ]
    }
   ],
   "source": [
    "!head -n 10 data/SMSSpamCollection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>spam</td>\n",
       "      <td>FreeMsg Hey there darling it's been 3 week's n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ham</td>\n",
       "      <td>Even my brother is not like to speak with me. ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            message\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...\n",
       "5  spam  FreeMsg Hey there darling it's been 3 week's n...\n",
       "6   ham  Even my brother is not like to speak with me. ..."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages_df = pd.read_csv('./data/SMSSpamCollection', sep='\\t',\n",
    "                           names=[\"label\", \"message\"])\n",
    "\n",
    "messages_df.head(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `Clean up our messages with some NLP before modeling`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "english_stopwords = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "wordnet_lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_messages(msg):\n",
    "    msg = msg.lower()\n",
    "    msg_tokens = nltk.word_tokenize(msg)\n",
    "    #remove stopwords\n",
    "    clean_msg_tokens = [w for w in msg_tokens if w not in english_stopwords]\n",
    "    #remove puncuations\n",
    "    clean_msg_tokens_puct = [ w for w in clean_msg_tokens if w not in string.punctuation]\n",
    "    # lemmatize: deal with endings\n",
    "    lemmatized_token = [wordnet_lemmatizer.lemmatize(w) for w in  clean_msg_tokens_puct]\n",
    "    return lemmatized_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages_df['clean_message'] = messages_df.message.apply(clean_messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "      <th>clean_message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>[go, jurong, point, crazy.., available, bugis,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>[ok, lar, ..., joking, wif, u, oni, ...]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>[free, entry, 2, wkly, comp, win, fa, cup, fin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>[u, dun, say, early, hor, ..., u, c, already, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>[nah, n't, think, go, usf, life, around, though]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            message  \\\n",
       "0   ham  Go until jurong point, crazy.. Available only ...   \n",
       "1   ham                      Ok lar... Joking wif u oni...   \n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "3   ham  U dun say so early hor... U c already then say...   \n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...   \n",
       "\n",
       "                                       clean_message  \n",
       "0  [go, jurong, point, crazy.., available, bugis,...  \n",
       "1           [ok, lar, ..., joking, wif, u, oni, ...]  \n",
       "2  [free, entry, 2, wkly, comp, win, fa, cup, fin...  \n",
       "3  [u, dun, say, early, hor, ..., u, c, already, ...  \n",
       "4   [nah, n't, think, go, usf, life, around, though]  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if/else converting labels to binary\n",
    "y = np.where(messages_df.label == 'ham', 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_string_messages = messages_df.clean_message.apply(' '.join).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `Train/Test split:`\n",
    "\n",
    "+ If you don't have enough data this will be a problem with your accuracy\n",
    "\n",
    "+ Leaving to little data left for the test set, you will also have problems with your accuracy as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:  3900\n",
      "X_test:  1672\n",
      "y_train:  3900\n",
      "y_test:  1672\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_string_messages, y, test_size = 0.3,\n",
    "    random_state = 37)\n",
    "print (\"X_train: \", len(X_train))\n",
    "print(\"X_test: \", len(X_test))\n",
    "print(\"y_train: \", len(y_train))\n",
    "print(\"y_test: \", len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `Count Vectorizer:`\n",
    "\n",
    "+ Convert a list/array of text documents into matrix of tokens. The dimensions will be the same as your vocabulary and keep a count of each word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                lowercase=True, max_df=1.0, max_features=1500, min_df=1,\n",
       "                ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = CountVectorizer()\n",
    "\n",
    "cv.fit(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3900x1500 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 25944 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_cv = cv.transform(X_train)\n",
    "X_train_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1672x1500 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 10963 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_cv = cv.transform(X_test)\n",
    "X_test_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `Explain what is going on below:`\n",
    "\n",
    "we are creating a variable `clf` which is storing our `Logistic Regression` model that will be used to make predictions on our data. \n",
    "\n",
    "+ `cv=5`: will be our cross validation (k-folds), here I chose 5.\n",
    "\n",
    "Why use this `Cross Validation` anyway?\n",
    "\n",
    "Well, it is useful for a few reasons: consider if you were splitting your data into `train/validate/split` this can drastically reduce the amount of data you have and if you don't have a heaping gluttonous amount of data then maybe you would need to remove the validation step.\n",
    "\n",
    "You can use the `CV` with the train/test model and still be alright. But, you have to choose what are called `folds` or more commonly `k-folds`. This is the amount of sets you will create by splitting up your data or (`k-smaller`) sets of data.\n",
    "\n",
    "+ The data are trained on **(k-1)** folds\n",
    "+ Then the resulting data are checked for instance on accuracy\n",
    "\n",
    "+ The result will be a performance of how your averaged `CV` was scored for that loop.\n",
    "\n",
    "**Basically, cv=5 splits the data 5 times and each run will split a different percent train/test and in the end give back an averaged result.** That result can be your accuracy for instance. \n",
    "\n",
    "\n",
    "[sklearn doc for clarity](https://scikit-learn.org/stable/modules/cross_validation.html)\n",
    "\n",
    "Now the model will try to take our training data and generate a fit based on what we provide. \n",
    "\n",
    "+ After this step we have to taken unseen data `test set` that was with held and see how it predicts from what we initially learned. The result will be our accuracy in this case, which will show that we have a 98.5% chance of test data correctly labeling Ham/Spam.\n",
    "\n",
    "+ **Always, watchout for over/underfitting NO matter what you are doing! Good Life lesson ok---**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegressionCV(Cs=10, class_weight=None, cv=5, dual=False,\n",
      "                     fit_intercept=True, intercept_scaling=1.0, l1_ratios=None,\n",
      "                     max_iter=200, multi_class='auto', n_jobs=None,\n",
      "                     penalty='l2', random_state=None, refit=True,\n",
      "                     scoring='accuracy', solver='lbfgs', tol=0.0001, verbose=0)\n",
      "Train Scoring:  0.9992307692307693\n"
     ]
    }
   ],
   "source": [
    "# convert/cast type as int\n",
    "y_train=y_train.astype('int')\n",
    "y_test=y_test.astype('int')\n",
    "\n",
    "# Cross Val. with Log Regr.\n",
    "clf=LogisticRegressionCV(cv=5,max_iter=200,scoring='accuracy')\n",
    "\n",
    "print(clf.fit(X_train_cv,y_train))\n",
    "print(\"Train Scoring ('Accuracy'): \",clf.score(X_train_cv,y_train))\n",
    "\n",
    "LogisticRegressionCV()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `3 ways to do the same thing: `\n",
    "\n",
    "+ **Predict Ham/spam: using Logistic Regression**\n",
    "\n",
    "+ `Accuracy:` number_correctly_labeled_oberservations / total_oberservations\n",
    "\n",
    "Can think of it like this:\n",
    "\n",
    "`Accuracy` = (TP+TN) / (TP+FP+FN+TN)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "|        \t|          \t| **Predicted**      \t| Predicted      \t|\n",
    "|--------\t|----------\t|----------------\t|----------------\t|\n",
    "|        \t|          \t| `Negative`       \t| `Positive`       \t|\n",
    "| **Actual** \t| `Positive` \t| FN \t| TP  \t|\n",
    "    | **Actual** \t| `Negative` \t| TN  \t| FP \t|\n",
    "    \n",
    "`----------------------`\n",
    "\n",
    "**`A side not:`** if the amount of false negative and false positive are fairly close, than you have a good chance that `accuracy` will be a good call. But, if they are very different when compared to each other consider using F1-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9856459330143541"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "clf.score(X_test_cv,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9856459330143541"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(clf.predict(X_test_cv),y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9856459330143541"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# By Hand:\n",
    "np.sum(np.argmax(clf.predict_proba(X_test_cv),axis=1)==y_test)/len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `Describe our Metrics:`\n",
    "\n",
    "+ `Precision:` ratio predicted positive observations to total positive predicted observations\n",
    "\n",
    "`Precision = TP / (TP + FP)`\n",
    "\n",
    "+ `Recall:` sensitivity, correctly predicted positive observations to all observations in actual class.\n",
    "\n",
    "`Recall = TP/(TP+FN)`, where the true positive = (TP+FP)\n",
    "\n",
    "I need to explain two valid and important points here:\n",
    "\n",
    "1.) If you have a bank that is looking at fraud detection and predicted to be negative, well that is a problems when indeed it was fraud. \n",
    "\n",
    "2.) Suppose you have a really bad virus, well like we have currently and you accidently predict that a sick person is not sick from some given test. Saying this would result in a False Negative and can be detrimental if you have a highly infectious disease.\n",
    "\n",
    "\n",
    "+  `F1-score:` weighted average of recall and precission, use when there are unbalanced class distribution. For example,  a large amount of true negatives: TN \n",
    "\n",
    "`F1-Score = 2*(Recall * Precision) / (Recall + Precision)`\n",
    "\n",
    "\n",
    "+ `Support:` frequency of items from all items that occur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.91      0.95       240\n",
      "           1       0.99      1.00      0.99      1432\n",
      "\n",
      "    accuracy                           0.99      1672\n",
      "   macro avg       0.99      0.96      0.97      1672\n",
      "weighted avg       0.99      0.99      0.99      1672\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test,clf.predict(X_test_cv)))\n",
    "\n",
    "# Ham=1 , spam=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`Outcome:`** \n",
    "\n",
    "+ We have a 98.5% `accuracy` meaning that from our data, we correctly predicted 98.5% of predicted observations/total observations \n",
    "\n",
    "+ We have a `precision` of 99% for both classes meaning that: we correctly predicted the positive observations to the total predicted positive observations.\n",
    "\n",
    "+ `Recall`, was 91% predicted for spam meaning that the true positives were correctly predicted 91% of the time using Logistic regression.\n",
    "\n",
    "+ `F1-score:` showed that the weighted ratio of precision and recall showed that 95% of the time spam was correctly labeled given we take into account false positive and false negatives.\n",
    "\n",
    "Overall, we can see that the f1-score would be something we should focus on and see what other models may reflect these data better, if possible. Depeding on what threshold you would like to meet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Acutal</th>\n",
       "      <th>Predicted</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>ham</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>spam</td>\n",
       "      <td>ham</td>\n",
       "      <td>FreeMsg Hey there darling it's been 3 week's n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ham</td>\n",
       "      <td>ham</td>\n",
       "      <td>Even my brother is not like to speak with me. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ham</td>\n",
       "      <td>ham</td>\n",
       "      <td>As per your request 'Melle Melle (Oru Minnamin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>spam</td>\n",
       "      <td>ham</td>\n",
       "      <td>WINNER!! As a valued network customer you have...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>spam</td>\n",
       "      <td>ham</td>\n",
       "      <td>Had your mobile 11 months or more? U R entitle...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Acutal Predicted                                            message\n",
       "0    ham       ham  Go until jurong point, crazy.. Available only ...\n",
       "1    ham       ham                      Ok lar... Joking wif u oni...\n",
       "2   spam       ham  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3    ham       ham  U dun say so early hor... U c already then say...\n",
       "4    ham       ham  Nah I don't think he goes to usf, he lives aro...\n",
       "5   spam       ham  FreeMsg Hey there darling it's been 3 week's n...\n",
       "6    ham       ham  Even my brother is not like to speak with me. ...\n",
       "7    ham       ham  As per your request 'Melle Melle (Oru Minnamin...\n",
       "8   spam       ham  WINNER!! As a valued network customer you have...\n",
       "9   spam       ham  Had your mobile 11 months or more? U R entitle..."
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ham=1, spam=0\n",
    "ham_spam=pd.DataFrame(list(zip(y,  clf.predict(X_test_cv))),columns=['Actual','Predicted'])\n",
    "\n",
    "ham_spam.head(10)\n",
    "\n",
    "actual=np.where(ham_spam.Actual == 1, 'ham','spam')\n",
    "predicted=np.where(ham_spam.Predicted == 1, 'ham','spam')\n",
    "ham_spam_updt=pd.DataFrame(list(zip(actual,predicted)),columns=['Acutal','Predicted'])\n",
    "\n",
    "pd.concat([ham_spam_updt,messages_df.iloc[:1672,1]],axis=1).head(10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=red>Like</font>, Share &\n",
    "\n",
    "# <font color=red>SUB</font>scribe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Citations & Help:\n",
    "\n",
    "# ◔̯◔\n",
    "\n",
    "https://machinelearningmastery.com/a-gentle-introduction-to-scikit-learn-a-python-machine-learning-library/\n",
    "\n",
    "https://towardsdatascience.com/spam-classifier-in-python-from-scratch-27a98ddd8e73\n",
    "\n",
    "https://www.kaggle.com/snehithatiger/spam-or-ham-classification\n",
    "\n",
    "https://adataanalyst.com/scikit-learn/countvectorizer-sklearn-example/\n",
    "\n",
    "https://machinelearningmastery.com/prepare-text-data-machine-learning-scikit-learn/\n",
    "\n",
    "https://www.youtube.com/watch?v=RZYjsw6P4nI\n",
    "\n",
    "https://towardsdatascience.com/natural-language-processing-count-vectorization-with-scikit-learn-e7804269bb5e\n",
    "\n",
    "https://blog.exsilio.com/all/accuracy-precision-recall-f1-score-interpretation-of-performance-measures/\n",
    "\n",
    "https://towardsdatascience.com/accuracy-precision-recall-or-f1-331fb37c5cb9\n",
    "\n",
    "https://towardsdatascience.com/association-rules-2-aa9a77241654"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
